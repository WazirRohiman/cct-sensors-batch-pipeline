{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Staged Data EDA\n",
    "\n",
    "This notebook analyzes the staged air quality data to verify the staging pipeline worked correctly.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect all staged air quality Parquet files\n",
    "2. Verify data quality and structure\n",
    "3. Check station mapping with surrogate keys\n",
    "4. Analyze temporal coverage and data completeness\n",
    "5. Compare with expected outputs from staging pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Discover Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "staged_dir = Path(\"/home/jovyan/work/data/staged\")\n",
    "config_dir = Path(\"/home/jovyan/work/src/configs\")\n",
    "\n",
    "# Load station mapping configuration\n",
    "with open(config_dir / \"station_mapping.yaml\", 'r') as f:\n",
    "    station_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Staged data directory: {staged_dir}\")\n",
    "print(f\"Directory exists: {staged_dir.exists()}\")\n",
    "\n",
    "# Discover all air quality staged files\n",
    "air_quality_files = list(staged_dir.glob(\"air_quality_*.parquet\"))\n",
    "print(f\"\\nFound {len(air_quality_files)} air quality staged files:\")\n",
    "for file in sorted(air_quality_files):\n",
    "    print(f\"  - {file.name} ({file.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Station Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station mappings\n",
    "stations = station_config['wind_stations']['station_mappings']\n",
    "air_quality_metrics = station_config['air_quality_metrics']\n",
    "\n",
    "# Create station lookup\n",
    "station_lookup = {station['station_pk']: station for station in stations}\n",
    "pollutant_lookup = {metric['metric_code']: metric for metric in air_quality_metrics}\n",
    "\n",
    "print(\"Station Mapping:\")\n",
    "for pk, station in station_lookup.items():\n",
    "    print(f\"  {pk}: {station['station_name']} ({station['station_code']})\")\n",
    "\n",
    "print(\"\\nAir Quality Pollutants:\")\n",
    "for code, metric in pollutant_lookup.items():\n",
    "    print(f\"  {code}: {metric['metric_name']} ({metric['unit']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Analyze All Staged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all air quality files\n",
    "air_quality_data = {}\n",
    "file_summary = []\n",
    "\n",
    "for file_path in sorted(air_quality_files):\n",
    "    try:\n",
    "        # Extract pollutant and year from filename\n",
    "        filename = file_path.stem\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            pollutant = parts[2]  # air_quality_[pollutant]_year\n",
    "            year = parts[3] if len(parts) >= 4 else 'unknown'\n",
    "        else:\n",
    "            pollutant = 'unknown'\n",
    "            year = 'unknown'\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Store in dictionary\n",
    "        key = f\"{pollutant}_{year}\"\n",
    "        air_quality_data[key] = df\n",
    "        \n",
    "        # Collect summary info - split the line for length\n",
    "        date_info = \"No datetime\"\n",
    "        if 'datetime' in df.columns:\n",
    "            date_info = (\n",
    "                f\"{df['datetime'].min().date()} to \"\n",
    "                f\"{df['datetime'].max().date()}\"\n",
    "            )\n",
    "        \n",
    "        file_summary.append({\n",
    "            'file': file_path.name,\n",
    "            'pollutant': pollutant,\n",
    "            'year': year,\n",
    "            'rows': len(df),\n",
    "            'columns': len(df.columns),\n",
    "            'date_range': date_info,\n",
    "            'memory_mb': df.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {key}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path.name}: {e}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(file_summary)\n",
    "print(f\"\\nLoaded {len(air_quality_data)} datasets successfully\")\n",
    "print(f\"Total memory usage: {summary_df['memory_mb'].sum():.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display file summary\n",
    "print(\"File Summary:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Air Quality Staged Data Analysis', fontsize=16)\n",
    "\n",
    "# 1. File count by year and pollutant\n",
    "if len(summary_df) > 0:\n",
    "    year_pollutant_counts = (\n",
    "        summary_df.groupby(['year', 'pollutant'])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    year_pollutant_counts.plot(kind='bar', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Files by Year and Pollutant')\n",
    "    axes[0,0].set_xlabel('Year')\n",
    "    axes[0,0].set_ylabel('Number of Files')\n",
    "    axes[0,0].legend(\n",
    "        title='Pollutant', \n",
    "        bbox_to_anchor=(1.05, 1), \n",
    "        loc='upper left'\n",
    "    )\n",
    "\n",
    "# 2. Data volume by dataset\n",
    "if len(summary_df) > 0:\n",
    "    summary_df.plot(x='file', y='rows', kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Records per Dataset')\n",
    "    axes[0,1].set_xlabel('Dataset')\n",
    "    axes[0,1].set_ylabel('Number of Records')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Simple data overview\n",
    "overview_text = (\n",
    "    f'Total Files: {len(air_quality_files)}\\\\n'\n",
    "    f'Total Records: {summary_df[\"rows\"].sum():,}\\\\n'\n",
    "    f'Years: {\", \".join(sorted(summary_df[\"year\"].unique()))}\\\\n'\n",
    "    f'Pollutants: {\", \".join(sorted(summary_df[\"pollutant\"].unique()))}'\n",
    ")\n",
    "axes[1,0].text(\n",
    "    0.5, 0.5, overview_text, \n",
    "    ha='center', va='center', fontsize=12, \n",
    "    transform=axes[1,0].transAxes\n",
    ")\n",
    "axes[1,0].set_title('Data Overview')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "# 4. Memory usage\n",
    "if len(summary_df) > 0:\n",
    "    summary_df.plot(x='pollutant', y='memory_mb', kind='bar', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Memory Usage by Pollutant')\n",
    "    axes[1,1].set_xlabel('Pollutant')\n",
    "    axes[1,1].set_ylabel('Memory (MB)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIR QUALITY STAGING PIPELINE VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# File statistics\n",
    "print(f\"\\nüìä DATA VOLUME:\")\n",
    "print(f\"  ‚Ä¢ Total staged files: {len(air_quality_files)}\")\n",
    "print(f\"  ‚Ä¢ Total records: {summary_df['rows'].sum():,}\")\n",
    "print(f\"  ‚Ä¢ Total memory usage: {summary_df['memory_mb'].sum():.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Years covered: {sorted(summary_df['year'].unique())}\")\n",
    "print(f\"  ‚Ä¢ Pollutants found: {sorted(summary_df['pollutant'].unique())}\")\n",
    "\n",
    "# Expected outputs validation\n",
    "expected_years = ['2019', '2020', '2021', '2022']\n",
    "expected_pollutants = ['no2', 'o3', 'pm10', 'pm25', 'so2']\n",
    "\n",
    "# Note: 2019 may not have PM2.5\n",
    "expected_files_2019 = ['no2', 'o3', 'pm10', 'so2']  # 4 files\n",
    "expected_files_2020_plus = ['no2', 'o3', 'pm10', 'pm25', 'so2']  # 5 files each\n",
    "\n",
    "print(f\"\\nüéØ VALIDATION RESULTS:\")\n",
    "actual_files_by_year = summary_df.groupby('year')['pollutant'].count()\n",
    "# Split long calculation across lines\n",
    "files_2019 = len(expected_files_2019)\n",
    "files_other_years = (len(expected_years) - 1) * len(expected_files_2020_plus)\n",
    "total_expected_files = files_2019 + files_other_years\n",
    "total_actual_files = len(air_quality_files)\n",
    "\n",
    "validation_passed = total_actual_files == total_expected_files\n",
    "print(f\"  ‚Ä¢ Expected total files: {total_expected_files}\")\n",
    "print(f\"  ‚Ä¢ Actual total files: {total_actual_files}\")\n",
    "status_text = 'PASSED' if validation_passed else 'FAILED'\n",
    "print(f\"  ‚Ä¢ File count validation: {status_text}\")\n",
    "\n",
    "print(f\"\\nüöÄ STATUS:\")\n",
    "if validation_passed:\n",
    "    print(f\"  ‚Ä¢ ‚úÖ Air quality staging pipeline working correctly\")\n",
    "    print(f\"  ‚Ä¢ ‚úÖ Ready to proceed with normalization pipeline\")\n",
    "    print(f\"  ‚Ä¢ ‚úÖ Data structure ready for analysis\")\n",
    "else:\n",
    "    print(f\"  ‚Ä¢ ‚ùå Review staging pipeline for issues\")\n",
    "\n",
    "final_status = 'SUCCESS' if validation_passed else 'NEEDS REVIEW'\n",
    "print(f\"\\nüìù STAGING PIPELINE STATUS: {final_status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}